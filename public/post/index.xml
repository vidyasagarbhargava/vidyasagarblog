<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Vidyasagar Bhargava</title>
    <link>/post/</link>
    <description>Recent content in Posts on Vidyasagar Bhargava</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hypothesis Testing made simple</title>
      <link>/2019/06/hypothesis-testing-made-simple/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/hypothesis-testing-made-simple/</guid>
      <description>In this post we will use a very elegant and simple approach to test any hypothesis. The approach is based on growing trend of emphasizingdata and simulations instead of classical probability theory and complex statistical tests. Since We know that its hard to wrap the head around how to reject null hypotheses and interpret p-values.

The new approach however has this philosphy that there is only one statistical test and that at their core, all statistical tests (be they t-tests, chi-squared tests, signed Wilcoxon rank tests, etc.</description>
    </item>
    
    <item>
      <title>Gradient Descent from scratch and visualization</title>
      <link>/2019/06/gradient-descent-from-scratch-and-visualization/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/gradient-descent-from-scratch-and-visualization/</guid>
      <description>Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks.
Below video discusses about gradient descent algorithm. Its good to spend some time on this video and get intuition about it before we start writing code for it.</description>
    </item>
    
    <item>
      <title>Machine Learning in Python</title>
      <link>/2019/06/machine-learning-in-python/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/machine-learning-in-python/</guid>
      <description>In this blog post we will see introduction to machine learning using python. We will train model on two different datasets using two different type of machine learning algorithm one for classifier and other for regression.The learning algorithm finds the pattern in the training data which maps the input data features to target variable and it outputs an machine learning model that captures these patterns. Also we will learn about scikit-learn library in detail (coming soon).</description>
    </item>
    
    <item>
      <title>Softmax function from scratch</title>
      <link>/2019/06/softmax-function-from-scratch/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/softmax-function-from-scratch/</guid>
      <description>Softmax is a generalization of logistic regression which can be use for multi-class classification. The softmax function squashes the outputs of each unit to be between 0 and 1, just like a sigmoid function. But it also divides each output such that the total sum of the outputs is equal to 1.
Softmax Function :-
Softmax is a generalization of logistic regression which can be use for multi-class classification.</description>
    </item>
    
    <item>
      <title>Learn Machine Learning using Kaggle Competition titanic ðŸš¢ dataset</title>
      <link>/2019/06/learn-machine-learning-using-kaggle-competition-titanic-dataset/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/learn-machine-learning-using-kaggle-competition-titanic-dataset/</guid>
      <description>This post is an effort of showing an approach of Machine learning in R using tidyverse and tidymodels. We will go through step by step from data import to final model evaluation process in machine learning. We will not just focus on coding part but also the statistical aspect should be taken into account behind the modelling process. In this tutorial we are using titanic dataset from Kaggle competition.</description>
    </item>
    
    <item>
      <title>Animation in R</title>
      <link>/2019/05/animation-in-r/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/animation-in-r/</guid>
      <description>Nowadays many data scientist are beginning to think about how to make their visualization more compelling with animation. Animation might help a viewer work through the logic behind anidea by showing the intermediate steps and transitions, or show how data collected over time changes. A moving image might offer a fresh perspective, or invite users to look deeper into the data presented. An animation might also smooth the change between two views, even if there is no temporal component to the data.</description>
    </item>
    
  </channel>
</rss>